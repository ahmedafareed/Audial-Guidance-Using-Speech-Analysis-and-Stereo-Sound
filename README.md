# Audial Guidance Using Speech Analysis and Stereo Sound

The aim of this work is to guide visually impaired users
in an area that has not been visited using a combined stereo
audio feedback system. This system takes as an input, the
vision features for object detection over and above the scene
the user is looking at. In the last step, it generates a descriptive
spoken narration (natural language, 3D audio spatialization)
to offer a naturalized navigation behavior. The system is built
upon the following key components:

## 1-Speech Analysis:
The system uses Text-to-Speech (TTS) models to convert the recognition of visual objects to ver-
balizations, so the objects recognized can be read by sound(auditory information).

## 2-Stereo Sound: 
A stereophonic 2-channel audio system and Head-Related Transfer Functions (HRTFs) are implemented to realize directional and binauralized, immersive auditory effect.
That makes it possible to localize and measure the distance of bjects in the scene accurate.
## 3-Volume Mapping: 
To approximate the induction of the distance sensation the depth of detected objects is in turn mapped to the variation in the audio volume change. This mapping is useful for the userâ€™s perception of the environment,considering the distance between the user and objects in front of him.

## Audial Guidance:
The system will be able to provideclear, easily discernible audio instructions and directions to understand, navigate, and accomplish tasks.

